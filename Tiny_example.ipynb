{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ee3bdcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from setfit.modeling import SetFitBaseModel, SKLearnWrapper, sentence_pairs_generation\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from transformers import pipeline, AutoTokenizer, AutoModel, AlbertForMaskedLM, RobertaForMaskedLM, RobertaForSequenceClassification\n",
    "\n",
    "from datasets import Dataset, load_dataset\n",
    "import copy\n",
    "from torch.utils.data import DataLoader\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b44e3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generates_achor(sentences, labels, template_dict, LABELS, input_pair):\n",
    "\n",
    "#InputExample(texts=['Anchor 2', 'Positive 2', 'Negative 2'])]\n",
    "    \n",
    "    for first_idx in range(len(sentences)):\n",
    "        current_sentence = sentences[first_idx]\n",
    "        current_label = labels[first_idx]\n",
    "        # get the achor template\n",
    "        anchor = template_dict[current_label]\n",
    "        second_sentence=np.random.choice(np.array(sentences)[np.array(labels)!=current_label])\n",
    "        \n",
    "\n",
    "        input_pair.append(InputExample(texts=[anchor, current_sentence, second_sentence]))\n",
    "          \n",
    "    return input_pair\n",
    "\n",
    "def generate_anchors(template: str, labels: list) -> dict:\n",
    "    dicts = {}\n",
    "    for i in range(len(labels)):\n",
    "        dicts[i] = template + labels[i]\n",
    "    \n",
    "    return dicts\n",
    "\n",
    "class BaseModel:\n",
    "    def __init__(self,  model, max_seq_length: int, add_normalization_layer: bool) -> None:\n",
    "        self.model = SentenceTransformer(model)\n",
    "        self.model_original_state = copy.deepcopy(self.model.state_dict())\n",
    "        self.model.max_seq_length = max_seq_length\n",
    "\n",
    "        if add_normalization_layer:\n",
    "            self.model._modules[\"2\"] = models.Normalize()\n",
    "        \n",
    "\n",
    "        \n",
    "class RunFewShot:\n",
    "    def __init__(self) -> None:\n",
    "        # Configure loss function\n",
    "        self.loss_class = losses.TripletLoss\n",
    "        # hyperparamiter\n",
    "        self.margin =0.25\n",
    "        self.max_seq_length=128\n",
    "        self.num_itaration=20\n",
    "\n",
    "        \n",
    "        self.model_wrapper = BaseModel(\n",
    "            \"paraphrase-mpnet-base-v2\", max_seq_length=self.max_seq_length, add_normalization_layer=False\n",
    "        )\n",
    "        self.model = self.model_wrapper.model\n",
    "                \n",
    "                    \n",
    "    def get_classifier(self, sbert_model: SentenceTransformer) -> SKLearnWrapper:\n",
    "        classifier = LogisticRegression()        \n",
    "        return SKLearnWrapper(sbert_model, classifier)\n",
    "\n",
    "    def train(self, data: Dataset, LABELS: dict, template: str) -> SKLearnWrapper:\n",
    "        \n",
    "        self.model.load_state_dict(copy.deepcopy(self.model_wrapper.model_original_state))\n",
    "\n",
    "        x_train = data[\"text\"]\n",
    "        y_train = data[\"label\"]        \n",
    "\n",
    "        # sentence-transformers adaptation\n",
    "        batch_size = 16\n",
    "        \n",
    "        ## Add TripeLoss\n",
    "        train_loss = self.loss_class(\n",
    "            model=self.model,\n",
    "            distance_metric=losses.TripletDistanceMetric.COSINE,\n",
    "            triplet_margin=self.margin,\n",
    "                    )\n",
    "        train_examples = []\n",
    "        for _ in range(self.num_itaration):\n",
    "            # cahnges how to generate input pairs to fit achor\n",
    "            dict_templates=generate_anchors(template,LABELS)\n",
    "            train_examples = sentence_generates_achor(np.array(x_train), y_train, dict_templates, LABELS, train_examples)\n",
    "        \n",
    "        train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=batch_size)\n",
    "        train_steps = len(train_dataloader)\n",
    "\n",
    "        \n",
    "        warmup_steps = math.ceil(train_steps * 0.1)\n",
    "        self.model.fit(\n",
    "            train_objectives=[(train_dataloader, train_loss)],\n",
    "            epochs=1,\n",
    "            steps_per_epoch=train_steps,\n",
    "            warmup_steps=warmup_steps,\n",
    "            show_progress_bar=False,\n",
    "        )\n",
    "        \n",
    "\n",
    "        # Train the final classifier\n",
    "        classifier = self.get_classifier(self.model)\n",
    "        classifier.fit(x_train, y_train)\n",
    "        return classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b51df3b",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "431dd32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load your csv file or other, here is jsut a small hand crafted data example (some samples from SST2)\n",
    "\n",
    "text = ['lend some dignity to a dumb story', 'The plot is nothing but boilerplate clich√©s from start to finish','I hate over happy endings', 'Grant and Bullock are so good together', 'Emma Watson really fulfilled the role', ' The actoring was really good']\n",
    "label = [1,1,1,0,0,0]\n",
    "dict_label =  {0:'positve', 1:'negative'}\n",
    "df_train = pd.DataFrame({'text': text,'label':label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f5b821fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = Dataset.from_pandas(df_train, preserve_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "bb26c6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = 'The movie review is '\n",
    "label_names = ['positive', 'negative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b490b825",
   "metadata": {},
   "outputs": [],
   "source": [
    "ancSetfit = RunFewShot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "13499d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = ancSetfit .train(data_train, label_names, template)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e94244d",
   "metadata": {},
   "source": [
    "### predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "56aaafb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load your csv file, here is jsut a small data example\n",
    "text_pred = ['This wat not the best actoring from Mads Mikkelsen', 'the story line is very weak', 'Mads Mikkelsen was really a good choice', 'the story line is really cool']\n",
    "df_pred = pd.DataFrame({'text': text_pred})\n",
    "data_pred = Dataset.from_pandas(df_pred, preserve_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d0157486",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "y_pred = classifier.predict(data_pred['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a69b3379",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred['pred_sentiment'] = pd.Series(y_pred).map(dict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "17618b71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>pred_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This wat not the best actoring from Mads Mikke...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the story line is very weak</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mads Mikkelsen was really a good choice</td>\n",
       "      <td>positve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the story line is really cool</td>\n",
       "      <td>positve</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text pred_sentiment\n",
       "0  This wat not the best actoring from Mads Mikke...       negative\n",
       "1                        the story line is very weak       negative\n",
       "2            Mads Mikkelsen was really a good choice        positve\n",
       "3                      the story line is really cool        positve"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aebd289",
   "metadata": {},
   "source": [
    "### What if we have the same training data, but the 1,0 is not about sentiment but topic \n",
    "Now imagine that with the small training data, the thing we wanted to classify from the 0 and 1 where not sentiment, but in fact wheter the movie review was concern with actors or plot?\n",
    "Try to classify this ny only changing the anchor statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ebe7c899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new anchor statement\n",
    "dict_label_topic =  {0:'actors', 1: 'plot'}\n",
    "template = 'The movie review is concerning '\n",
    "label_names = ['the actors', 'the plot']\n",
    "# train\n",
    "classifier_topic = ancSetfit .train(data_train, label_names, template)\n",
    "\n",
    "# predict\n",
    "y_pred_topic = classifier_topic.predict(data_pred['text'])\n",
    "df_pred['pred_topic'] = pd.Series(y_pred_topic).map(dict_label_topic)\n",
    "\n",
    "# print\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1c30b5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred['pred_topic'] = pd.Series(y_pred_topic).map(dict_label_topic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f2ca672f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>pred_sentiment</th>\n",
       "      <th>pred_topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This wat not the best actoring from Mads Mikke...</td>\n",
       "      <td>negative</td>\n",
       "      <td>actors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the story line is very weak</td>\n",
       "      <td>negative</td>\n",
       "      <td>plot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mads Mikkelsen was really a good choice</td>\n",
       "      <td>positve</td>\n",
       "      <td>actors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the story line is really cool</td>\n",
       "      <td>positve</td>\n",
       "      <td>plot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text pred_sentiment pred_topic\n",
       "0  This wat not the best actoring from Mads Mikke...       negative     actors\n",
       "1                        the story line is very weak       negative       plot\n",
       "2            Mads Mikkelsen was really a good choice        positve     actors\n",
       "3                      the story line is really cool        positve       plot"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3a035a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0103cfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fa9305",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
